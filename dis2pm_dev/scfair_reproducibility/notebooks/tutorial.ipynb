{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b3a7803-1eb4-49c2-b183-470e391b72c2",
   "metadata": {},
   "source": [
    "# scFair tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f39833-c4fa-4ed4-a0da-491e1263b0b7",
   "metadata": {},
   "source": [
    "# install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcdb06c-80f9-4241-a244-94c74884036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required packages (run in terminal)\n",
    "pip install torch torchvision torchaudio\n",
    "pip install scvi-tools\n",
    "pip install matplotlib\n",
    "pip install scanpy\n",
    "pip install scikit-misc\n",
    "pip install xgboost\n",
    "pip install fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a091480f-ee57-4161-8e3f-90c20870ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install scfair (run in terminal)\n",
    "pip install git+https://github.com/M0hammadL/scfair.git\n",
    "\n",
    "# clone scfair-reproducibility (run in terminal)\n",
    "git clone https://github.com/M0hammadL/scfair-reproducibility.git\n",
    "# then rename the cloned directory to: scfair_reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58390afc-8d63-4fac-8a66-86453d4f8a2d",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ca178d8-6191-4851-a095-6676a6852d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "\n",
    "import scvi\n",
    "scvi.settings.seed = 0\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44933fca-7597-4382-9a26-f3e8701fd00d",
   "metadata": {},
   "source": [
    "# check if you are in a child of the project directory, and if so, change to the main directory: scfair-reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59a0dae2-6691-465c-b307-43f5cc240f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/analysis/scfair_analysis/scfair-reproducibility/notebooks\n",
      "/home/jupyter/analysis/scfair_analysis/scfair-reproducibility\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "!pwd\n",
    "path_current = os.getcwd()\n",
    "print(path_current.split('/')[-1])\n",
    "if path_current.split('/')[-1]==\"scfair-reproducibility\":\n",
    "    print(\"we are in the correct directory\")\n",
    "else:\n",
    "    os.chdir(\"..\")\n",
    "    print(\"we are changing directory to\")\n",
    "    !pwd\n",
    "    \n",
    "    \n",
    "from evaluation.metrics import *\n",
    "from evaluation.evaluate import *\n",
    "from scib_metrics_dev.src.scib_metrics.benchmark import Benchmarker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3e8218-c307-4b60-8fc9-356b58b2779e",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21c82ec4-f43d-4a01-a418-1782e283e698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m File data/hca_subsampled_20k.h5ad already downloaded                                                      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 18641 × 1200\n",
       "    obs: 'NRP', 'age_group', 'cell_source', 'cell_type', 'donor', 'gender', 'n_counts', 'n_genes', 'percent_mito', 'percent_ribo', 'region', 'sample', 'scrublet_score', 'source', 'type', 'version', 'cell_states', 'Used', 'cell_type_idx', 'cell_source_idx', 'gender_idx', 'region_idx'\n",
       "    var: 'gene_ids-Harvard-Nuclei', 'feature_types-Harvard-Nuclei', 'gene_ids-Sanger-Nuclei', 'feature_types-Sanger-Nuclei', 'gene_ids-Sanger-Cells', 'feature_types-Sanger-Cells', 'gene_ids-Sanger-CD45', 'feature_types-Sanger-CD45', 'n_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
       "    uns: 'cell_type_colors', 'log1p', 'hvg'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "adata = scvi.data.heart_cell_atlas_subsampled()\n",
    "\n",
    "# preprocess dataset\n",
    "sc.pp.filter_genes(adata, min_counts=3)\n",
    "adata.layers[\"counts\"] = adata.X.copy()\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "adata.raw = adata\n",
    "sc.pp.highly_variable_genes(\n",
    "    adata,\n",
    "    n_top_genes=1200,\n",
    "    subset=True,\n",
    "    layer=\"counts\",\n",
    "    flavor=\"seurat_v3\",\n",
    ")\n",
    "\n",
    "# specify name of dataset \n",
    "data_name = 'heartAtlas'\n",
    "\n",
    "# specify attributes\n",
    "cats = ['cell_type', 'cell_source', 'gender', 'region']\n",
    "\n",
    "# specify a path that will be used to save any trained model later (directories in the path should be created first)\n",
    "pre_path = f\"models/FairVI\"\n",
    "\n",
    "# specify a path that will be used to save the preprocessed indices of paired samples for the counterfactual term calculation\n",
    "idx_cf_tensor_path = f'idx_cf_tensors/heart_4cov'\n",
    "\n",
    "# create numerical index for each attr in cats\n",
    "create_cats_idx(adata, cats)\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc750e2-b566-4d49-9b03-d2cdfcb8773d",
   "metadata": {},
   "source": [
    "# create directory for counterfactuals, named \"idx_cf_tensors\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eeb2421e-7a30-4983-bd81-34dcd215a542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory already exists!\n",
      "The models directory already exists!\n"
     ]
    }
   ],
   "source": [
    "# create directory with counterfactuals\n",
    "isExist = os.path.exists(idx_cf_tensor_path)\n",
    "if not isExist:\n",
    "    os.makedirs(idx_cf_tensor_path)\n",
    "    print(\"The new directory is created!\")\n",
    "else:\n",
    "    print(\"The directory already exists!\")\n",
    "\n",
    "# create directory with models\n",
    "isExist = os.path.exists(\"models\")\n",
    "if not isExist:\n",
    "    os.makedirs(idx_cf_tensor_path)\n",
    "    print(\"The models directory is created!\")\n",
    "else:\n",
    "    print(\"The models directory already exists!\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f3a92-c7b5-45cd-b725-8127e8da2bb5",
   "metadata": {},
   "source": [
    "# load/train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe21cf7-2120-4635-90b1-4c28cdc05c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m No backup URL provided for missing file                                                                   \n",
      "         models/FairVI/\u001b[1;36m2023\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m25\u001b[0m,heartAtlas,cell_type,cell_source,gender,region,\u001b[33mmax_epochs\u001b[0m=\u001b[1;36m400\u001b[0m,\u001b[33mbatch_size\u001b[0m=\u001b[1;36m256\u001b[0m,\u001b[33mcf_w\u001b[0m\n",
      "         \u001b[33meight\u001b[0m=\u001b[1;36m2\u001b[0m,\u001b[33malpha\u001b[0m=\u001b[1;36m1\u001b[0m,\u001b[33mclf_weight\u001b[0m=\u001b[1;36m50\u001b[0m,\u001b[33madv_clf_weight\u001b[0m=\u001b[1;36m10\u001b[0m,\u001b[33madv_period\u001b[0m=\u001b[1;36m1\u001b[0m,\u001b[33mmode\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m\u001b[35m/\u001b[0m\u001b[95mmodel.pt\u001b[0m                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/jupyter/analysis/scfair_analysis/scfair_analysis_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:321: RuntimeWarning: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/400:   7%|▋         | 29/400 [07:29<1:35:11, 15.39s/it, v_num=1, loss_validation=4.19e+3, x_0_validation=290, x_1_validation=298, x_2_validation=298, x_3_validation=298, x_4_validation=300, xcf_1_validation=316, xcf_2_validation=322, xcf_3_validation=316, xcf_4_validation=309, z_1_validation=20.6, z_2_validation=19.8, z_3_validation=20.9, z_4_validation=19.6, ce_validation=0.912, acc_validation=0.999, f1_validation=0.999, adv_ce_validation=1.33, adv_acc_validation=0.573, adv_f1_validation=0.573, loss_train=3.98e+3, x_0_train=280, x_1_train=291, x_2_train=291, x_3_train=290, x_4_train=292, xcf_1_train=298, xcf_2_train=304, xcf_3_train=299, xcf_4_train=296, z_1_train=21.4, z_2_train=20.6, z_3_train=21.5, z_4_train=20.1, ce_train=0.913, acc_train=0.999, f1_train=0.999, adv_ce_train=1.25, adv_acc_train=0.556, adv_f1_train=0.556]"
     ]
    }
   ],
   "source": [
    "# specify train parameters\n",
    "epochs = 400\n",
    "batch_size = 256\n",
    "cf_weight = 2\n",
    "alpha = 1\n",
    "clf_weight = 50\n",
    "adv_clf_weight = 10\n",
    "adv_period = 1\n",
    "mode=(0,1,2,3,4)\n",
    "\n",
    "train_dict = {'max_epochs': epochs, 'batch_size': batch_size, 'cf_weight': cf_weight,\n",
    "              'alpha': alpha, 'clf_weight': clf_weight, 'adv_clf_weight': adv_clf_weight,\n",
    "              'adv_period': adv_period, 'mode': mode}\n",
    "\n",
    "# specify a name for your model\n",
    "model_name = today + ',' + data_name + ',' + ','.join(cats) + ',' + ','.join(k + '=' + str(v) for k, v in train_dict.items())\n",
    "\n",
    "# load model (if trained before)\n",
    "try:\n",
    "    model = FairVI.load(f\"{pre_path}/{model_name}\", adata=adata)\n",
    "\n",
    "# trains the model (if not trained before) and save it into: pre_path + model_name\n",
    "except:\n",
    "\n",
    "    FairVI.setup_anndata(\n",
    "        adata,\n",
    "        layer='counts',\n",
    "        categorical_covariate_keys=cats,\n",
    "        continuous_covariate_keys=[]\n",
    "    )\n",
    "    model = FairVI(adata, idx_cf_tensor_path=idx_cf_tensor_path)\n",
    "    model.train(**train_dict)\n",
    "    model.save(f\"{pre_path}/{model_name}\")\n",
    "\n",
    "model.idx_cf_tensor_path = idx_cf_tensor_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bb95a3-4aa5-4cdd-9b85-35a572da24f6",
   "metadata": {},
   "source": [
    "# latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb75b9-09e1-4240-8d19-05f565fd3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains the model (if not trained before) and save it into: pre_path + model_name\n",
    "# then get latent representaion (they will be strored in adata.obsm)\n",
    "# Z_0 = adata.obsm[\"Z_0\"]\n",
    "# Z_i =  adata.obsm[\"Z_i\"] for i in [1, ..., len(cats)]\n",
    "# Z_{-i} = adata.obsm[\"Z _not_i\"] for i in [1, ..., len(cats)]\n",
    "model, adata = latent(\n",
    "        adata = adata,\n",
    "        cats = cats,\n",
    "        new_model_name = model_name,\n",
    "        pre_path = pre_path,\n",
    "        idx_cf_tensor_path = idx_cf_tensor_path,\n",
    "        plot_umap = True,\n",
    "        **train_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8531703-4dab-4163-8b63-bd943ba3e776",
   "metadata": {},
   "source": [
    "# Disentanglement/Fainess metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caadfb22-aed9-4a66-aaf2-42d2c0f635c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics for XGBoost classifier Si | Zi\n",
      "train acc S1: 1.0000,  test acc S1: 0.9987\n",
      "train acc S2: 1.0000,  test acc S2: 0.9991\n",
      "train acc S3: 1.0000,  test acc S3: 0.9995\n",
      "train acc S4: 1.0000,  test acc S4: 0.9979\n",
      "metrics for XGBoost classifier Si | (Z - Zi)\n",
      "train acc S1: 0.9985,  test acc S1: 0.7681\n",
      "train acc S2: 0.9903,  test acc S2: 0.7600\n",
      "train acc S3: 0.9402,  test acc S3: 0.7289\n",
      "train acc S4: 0.9658,  test acc S4: 0.4732\n",
      "fairness metrics wrt Si for XGBoost classifier NRP_idx_bin | (Z - Zi)\n",
      "i=1: accuracy = 0.9666, DP_diff = 0.0000, EO_diff = 0.0000\n",
      "i=2: accuracy = 0.8869, DP_diff = 0.0000, EO_diff = 1.0000\n",
      "i=3: accuracy = 0.9006, DP_diff = 0.0000, EO_diff = 0.0000\n",
      "i=4: accuracy = 0.9649, DP_diff = 0.0000, EO_diff = 0.0000\n",
      "Max_Dim Mutual Information metrics\n",
      "MI(Z_1 ; S_1) = 1.0728,  MI((Z - Z_1) ; S_1) = 0.3250\n",
      "MI(Z_2 ; S_2) = 1.1210,  MI((Z - Z_2) ; S_2) = 0.2348\n",
      "MI(Z_3 ; S_3) = 0.6677,  MI((Z - Z_3) ; S_3) = 0.0262\n",
      "MI(Z_4 ; S_4) = 0.9175,  MI((Z - Z_4) ; S_4) = 0.0759\n",
      "MIG = 0.6276\n",
      "Mixed_KSG Mutual Information metrics\n",
      "MI(Z_1 ; S_1) = 1.8780,  MI((Z - Z_1) ; S_1) = 0.6705, max MI((Z_j!=1) ; S_1) = 0.7601\n",
      "MI(Z_2 ; S_2) = 1.2580,  MI((Z - Z_2) ; S_2) = 0.3196, max MI((Z_j!=2) ; S_2) = 0.5715\n",
      "MI(Z_3 ; S_3) = 0.6887,  MI((Z - Z_3) ; S_3) = 0.1034, max MI((Z_j!=3) ; S_3) = 0.0845\n",
      "MI(Z_4 ; S_4) = 1.7533,  MI((Z - Z_4) ; S_4) = 0.3380, max MI((Z_j!=4) ; S_4) = 0.3246\n",
      "MIG = 0.7070, MIPG = 0.7602\n"
     ]
    }
   ],
   "source": [
    "# classifier Si | Zi\n",
    "acc_results_1 = clf_S_Z_metrics(adata, cats)\n",
    "# classifier Si | (Z - Zi)\n",
    "acc_results_2 = clf_S_Z_not_metrics(adata, cats)\n",
    "\n",
    "# fairness metrics: DP, EO, ...\n",
    "create_cats_idx(adata, ['NRP'])\n",
    "y_name = 'NRP_idx'\n",
    "ACC, DP_diff, EO_diff = fair_clf_metrics(adata, cats, y_name)\n",
    "\n",
    "# Max Mutual Information by taking Max over Dims\n",
    "MI_md, MI_not_md, mig_md = max_dim_MI_metrics(adata, cats)\n",
    "# Mutual Information by Mixed_KSG (https://github.com/wgao9/mixed_KSG/blob/master/mixed.py)\n",
    "MI, MI_not, MI_not_max, mig, mipg = Mixed_KSG_MI_metrics(adata, cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f939017-5428-456c-b13b-f1939b14ded8",
   "metadata": {},
   "source": [
    "# OOD metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f2a1e26-5889-466f-bd0a-3a386d6e38df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m No backup URL provided for missing file                                                                   \n",
      "         models/FairVI/\u001b[1;36m2023\u001b[0m-\u001b[1;36m08\u001b[0m-22T\u001b[1;92m18:12:51\u001b[0m.\u001b[1;36m733765\u001b[0m,heartAtlas,cell_type,cell_source,gender,region,\u001b[33mmax_epochs\u001b[0m=\u001b[1;36m400\u001b[0m,\u001b[33mbat\u001b[0m\n",
      "         \u001b[33mch_size\u001b[0m=\u001b[1;36m256\u001b[0m,\u001b[33mcf_weight\u001b[0m=\u001b[1;36m2\u001b[0m,\u001b[33malpha\u001b[0m=\u001b[1;36m1\u001b[0m,\u001b[33mclf_weight\u001b[0m=\u001b[1;36m50\u001b[0m,\u001b[33madv_clf_weight\u001b[0m=\u001b[1;36m10\u001b[0m,\u001b[33madv_period\u001b[0m=\u001b[1;36m1\u001b[0m,\u001b[33mmode\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m,            \n",
      "         \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m--cf--gender = Male to Female, cell_type = Ventricular_Cardiomyocyte, cell_source = Sanger-Nuclei,      \n",
      "         region = RV/model.pt                                                                                      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [MIG-GPU-18bbdf05-c7ca-a9f7-0896-7641c359d553/0/0]\n",
      "/lustre/scratch126/cellgen/team205/ks32/conda/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:321: RuntimeWarning: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/400:  12%|█▏        | 47/400 [07:28<55:31,  9.44s/it, v_num=1, loss_validation=4.16e+3, x_0_validation=285, x_1_validation=292, x_2_validation=293, x_3_validation=294, x_4_validation=294, xcf_1_validation=314, xcf_2_validation=313, xcf_3_validation=316, xcf_4_validation=310, z_1_validation=19.8, z_2_validation=18.3, z_3_validation=19.2, z_4_validation=18.5, ce_validation=0.913, acc_validation=0.998, f1_validation=0.998, adv_ce_validation=1.33, adv_acc_validation=0.577, adv_f1_validation=0.577, loss_train=3.99e+3, x_0_train=282, x_1_train=292, x_2_train=293, x_3_train=293, x_4_train=294, xcf_1_train=298, xcf_2_train=304, xcf_3_train=299, xcf_4_train=295, z_1_train=20.4, z_2_train=19.7, z_3_train=19.6, z_4_train=18.9, ce_train=0.913, acc_train=0.998, f1_train=0.998, adv_ce_train=1.19, adv_acc_train=0.559, adv_f1_train=0.559]  Epoch 00048: reducing learning rate of group 0 to 6.0000e-04.\n",
      "Epoch 62/400:  16%|█▌        | 62/400 [09:49<53:32,  9.50s/it, v_num=1, loss_validation=4.17e+3, x_0_validation=285, x_1_validation=292, x_2_validation=293, x_3_validation=294, x_4_validation=295, xcf_1_validation=315, xcf_2_validation=314, xcf_3_validation=317, xcf_4_validation=312, z_1_validation=18.7, z_2_validation=17.5, z_3_validation=17.7, z_4_validation=17.2, ce_validation=0.913, acc_validation=0.998, f1_validation=0.998, adv_ce_validation=1.32, adv_acc_validation=0.587, adv_f1_validation=0.587, loss_train=3.97e+3, x_0_train=281, x_1_train=291, x_2_train=291, x_3_train=292, x_4_train=293, xcf_1_train=296, xcf_2_train=301, xcf_3_train=296, xcf_4_train=293, z_1_train=19.3, z_2_train=18.6, z_3_train=18.5, z_4_train=17.9, ce_train=0.912, acc_train=0.999, f1_train=0.999, adv_ce_train=1.14, adv_acc_train=0.56, adv_f1_train=0.56]  \n",
      "Monitored metric loss_validation did not improve in the last 45 records. Best score: 4131.867. Signaling Trainer to stop.\n",
      "\u001b[34mINFO    \u001b[0m AnnData object appears to be a copy. Attempting to transfer setup.                                        \n",
      "Counterfactual prediction for gender = Male to Female, and cell_type = Ventricular_Cardiomyocyte, cell_source = Sanger-Nuclei, region = RV\n",
      "All Genes\n",
      "R2 = 0.8897\n",
      "R2 log = 0.8957\n",
      "DE Genes (n_top=100)\n",
      "R2 = 0.9104\n",
      "R2 log = 0.9165\n"
     ]
    }
   ],
   "source": [
    "cov_idx = 2  # index of target attribute in cats\n",
    "cov_value = 'Male'  # factual value for the target attribute\n",
    "cov_value_cf = 'Female'  # counterfactual value for the target attribute\n",
    "other_covs_values = ('Ventricular_Cardiomyocyte', 'Sanger-Nuclei', 'RV')  # fixed values for other attibutes that we perform OOD on them\n",
    "n_top_deg = 100  # number of top DE genes for R2 \n",
    "\n",
    "# holds-out all cells with other_covs_values (prefered method for OOD)\n",
    "# splits other cells to train/validation sets, trains the model, and finally perform OOD on held-out cells\n",
    "# returns: \n",
    "#     1) true genes counts vector by averaging all held-out cells\n",
    "#     2) predicted genes counts vector for average of held-out cells\n",
    "true_x_counts_mean, px_cf_mean_pred = ood_for_given_covs_2(\n",
    "        adata=adata,\n",
    "        cats=cats,\n",
    "        new_model_name=model_name,\n",
    "        pre_path=pre_path,\n",
    "        idx_cf_tensor_path=idx_cf_tensor_path,\n",
    "        cov_idx=cov_idx,\n",
    "        cov_value=cov_value,\n",
    "        cov_value_cf=cov_value_cf,\n",
    "        other_covs_values=other_covs_values,\n",
    "        n_top_deg=n_top_deg,\n",
    "        **train_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbcaf15-2676-44da-b88a-5ea85400b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you like to hold-out only cells with other_covs_values and cov_value_cf use:\n",
    "true_x_counts_mean, px_cf_mean_pred = ood_for_given_covs_1(\n",
    "        adata=adata,\n",
    "        cats=cats,\n",
    "        new_model_name=model_name,\n",
    "        pre_path=pre_path,\n",
    "        idx_cf_tensor_path=idx_cf_tensor_path,\n",
    "        cov_idx=cov_idx,\n",
    "        cov_value=cov_value,\n",
    "        cov_value_cf=cov_value_cf,\n",
    "        other_covs_values=other_covs_values,\n",
    "        n_top_deg=n_top_deg,\n",
    "        **train_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a6767b6-81e3-48d6-bb7b-bbcf169d377a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Genes\n",
      "R2 = 0.8956\n",
      "R2 log = 0.8955\n",
      "DE Genes (n_top=20)\n",
      "R2 = 0.9195\n",
      "R2 log = 0.9337\n"
     ]
    }
   ],
   "source": [
    "# R2 metrics (both ood_for_given_covs methods above use it)\n",
    "# you can try different values of n_top_deg\n",
    "r2_eval(adata, true_x_counts_mean, px_cf_mean_pred, n_top_deg=20)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "scfair_analysis_env",
   "name": "pytorch-gpu.1-13.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m110"
  },
  "kernelspec": {
   "display_name": "scfair_analysis_env",
   "language": "python",
   "name": "scfair_analysis_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
