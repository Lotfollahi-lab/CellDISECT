{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2996a46c-742a-45ae-b233-6070a8df96a6",
   "metadata": {},
   "source": [
    "Use the environment found on GCP at `conda activate /home/jupyter/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b229df-b8f9-435b-af68-f177151d16c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "\n",
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION']='python'\n",
    "\n",
    "import scvi\n",
    "scvi.settings.seed = 0\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from scipy.sparse import csr_matrix\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# import from scfair-reproducibility\n",
    "from scfair_reproducibility.benchmark_VAE.vi import VI\n",
    "from scfair_reproducibility.evaluation.metrics import *\n",
    "\n",
    "# import from scib_metrics\n",
    "from scfair_reproducibility.scib_metrics_dev.src.scib_metrics.benchmark import Benchmarker\n",
    "\n",
    "# other methods\n",
    "# import cpa\n",
    "# from data.biolord_dev.src import biolord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5cdceb8-7995-4dfe-9166-ec9327ad90b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "146ea27d-c50a-4c59-a6a6-203de0c4b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dis2pm.dis2pmvae import *\n",
    "from dis2pm.dis2pmvi import *\n",
    "from dis2pm.ood_m import *\n",
    "from dis2pm.trainingplan_m import *\n",
    "from dis2pm.utils_m import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5217720e-c7e9-4c02-8140-4f5581aaa13d",
   "metadata": {},
   "source": [
    "# prepare data: Heart Atlas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f396bc-3e8f-4b69-9321-d0f6fbd8cd43",
   "metadata": {},
   "source": [
    "Define function to convert covariate names to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23478535-4ebf-4333-b5aa-558bbb79cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cats_idx(adata, cats):\n",
    "    # create numerical index for each attr in cats\n",
    "\n",
    "    for i in range(len(cats)):\n",
    "        values = list(set(adata.obs[cats[i]]))\n",
    "\n",
    "        val_to_idx = {v: values.index(v) for v in values}\n",
    "\n",
    "        idx_list = [val_to_idx[v] for v in adata.obs[cats[i]]]\n",
    "\n",
    "        adata.obs[cats[i] + '_idx'] = pd.Categorical(idx_list)\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28d3c0e-cf1a-4380-9030-3392c1f54c51",
   "metadata": {},
   "source": [
    "Load and subsample the heart atlas dataset from Litvinukova et al. Nature 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fcb5d79-4b50-4b35-a29a-57cc1b366e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m File data/hca_subsampled_20k.h5ad already downloaded                                                      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/anndata/_core/anndata.py:1113: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if not is_categorical_dtype(df_full[k]):\n",
      "/home/jupyter/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/anndata/_core/anndata.py:1113: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if not is_categorical_dtype(df_full[k]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 18641 × 1200\n",
      "    obs: 'NRP', 'age_group', 'cell_source', 'cell_type', 'donor', 'gender', 'n_counts', 'n_genes', 'percent_mito', 'percent_ribo', 'region', 'sample', 'scrublet_score', 'source', 'type', 'version', 'cell_states', 'Used'\n",
      "    var: 'gene_ids-Harvard-Nuclei', 'feature_types-Harvard-Nuclei', 'gene_ids-Sanger-Nuclei', 'feature_types-Sanger-Nuclei', 'gene_ids-Sanger-Cells', 'feature_types-Sanger-Cells', 'gene_ids-Sanger-CD45', 'feature_types-Sanger-CD45', 'n_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "    uns: 'cell_type_colors', 'log1p', 'hvg'\n",
      "    layers: 'counts'\n",
      "  (0, 0)\t4.5277414\n",
      "  (3, 0)\t4.0320454\n",
      "  (4, 0)\t4.196429\n",
      "  (7, 0)\t2.1310735\n",
      "  (9, 0)\t1.2068739\n",
      "  (11, 0)\t2.9385843\n",
      "  (14, 0)\t3.3909585\n",
      "  (15, 0)\t4.0477786\n",
      "  (16, 0)\t5.345359\n",
      "  (18, 0)\t1.5867883\n",
      "  (20, 0)\t1.2203416\n",
      "  (21, 0)\t4.835906\n",
      "  (24, 0)\t2.8654125\n",
      "  (25, 0)\t2.3536403\n",
      "  (28, 0)\t2.6903114\n",
      "  (32, 0)\t1.9224532\n",
      "  (35, 0)\t2.4982107\n",
      "  (36, 0)\t2.6542559\n",
      "  (40, 0)\t3.4035203\n",
      "  (41, 0)\t1.0495343\n",
      "  (42, 0)\t4.854159\n",
      "  (49, 0)\t4.057851\n",
      "  (54, 0)\t1.5724111\n",
      "  (56, 0)\t5.04266\n",
      "  (63, 0)\t4.6200833\n",
      "  :\t:\n",
      "  (18579, 0)\t0.62361\n",
      "  (18581, 0)\t1.4707114\n",
      "  (18582, 0)\t5.3347993\n",
      "  (18583, 0)\t2.5793965\n",
      "  (18584, 0)\t2.1661913\n",
      "  (18586, 0)\t5.364441\n",
      "  (18587, 0)\t3.3751495\n",
      "  (18588, 0)\t2.7540352\n",
      "  (18591, 0)\t2.6405444\n",
      "  (18594, 0)\t4.4277444\n",
      "  (18596, 0)\t4.7266984\n",
      "  (18597, 0)\t4.284467\n",
      "  (18598, 0)\t2.2501295\n",
      "  (18601, 0)\t3.9314625\n",
      "  (18612, 0)\t4.6052694\n",
      "  (18614, 0)\t2.2388175\n",
      "  (18620, 0)\t4.426577\n",
      "  (18623, 0)\t2.071866\n",
      "  (18624, 0)\t2.4042833\n",
      "  (18626, 0)\t2.0940146\n",
      "  (18628, 0)\t2.6333194\n",
      "  (18629, 0)\t4.7779045\n",
      "  (18630, 0)\t1.7732518\n",
      "  (18632, 0)\t2.2247128\n",
      "  (18638, 0)\t4.3313503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/anndata/_core/merge.py:217: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(dtype):\n",
      "/home/jupyter/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/anndata/_core/merge.py:217: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5590.68177193 1019.82674909 1078.93260568 ... 7484.\n",
      "  7558.         8864.        ]]\n",
      "AnnData object with n_obs × n_vars = 18641 × 1200\n",
      "    obs: 'NRP', 'age_group', 'cell_source', 'cell_type', 'donor', 'gender', 'n_counts', 'n_genes', 'percent_mito', 'percent_ribo', 'region', 'sample', 'scrublet_score', 'source', 'type', 'version', 'cell_states', 'Used'\n",
      "    var: 'gene_ids-Harvard-Nuclei', 'feature_types-Harvard-Nuclei', 'gene_ids-Sanger-Nuclei', 'feature_types-Sanger-Nuclei', 'gene_ids-Sanger-Cells', 'feature_types-Sanger-Cells', 'gene_ids-Sanger-CD45', 'feature_types-Sanger-CD45', 'n_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "    uns: 'cell_type_colors', 'log1p', 'hvg'\n",
      "    layers: 'counts'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/anndata/_core/anndata.py:1113: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if not is_categorical_dtype(df_full[k]):\n"
     ]
    }
   ],
   "source": [
    "adata = scvi.data.heart_cell_atlas_subsampled()\n",
    "\n",
    "# preprocess dataset\n",
    "sc.pp.filter_genes(adata, min_counts=3)\n",
    "adata.layers[\"counts\"] = adata.X.copy()\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "adata.raw = adata\n",
    "sc.pp.highly_variable_genes(\n",
    "    adata,\n",
    "    n_top_genes=1200,\n",
    "    subset=True,\n",
    "    layer=\"counts\",\n",
    "    flavor=\"seurat_v3\",\n",
    ")\n",
    "\n",
    "print(adata)\n",
    "print(adata[:,1198].X)\n",
    "adata_atac = adata[:, -200:].copy()\n",
    "adata_rna = adata[:, :1000].copy()\n",
    "adata_obs = adata.obs.copy()\n",
    "adata_uns = adata.uns.copy()\n",
    "adata_atac.X.data = np.ones(adata_atac.X.data.shape)\n",
    "adata = ad.concat([adata_rna, adata_atac], axis=1)\n",
    "adata.obs = adata_obs\n",
    "adata.uns = adata_uns\n",
    "print(adata[:,:].X.sum(axis=0))\n",
    "print(adata)\n",
    "\n",
    "# specify name of dataset \n",
    "data_name = 'HeartAtlas'\n",
    "\n",
    "# specify attributes\n",
    "cats = ['cell_type', 'cell_source', 'gender', 'region']\n",
    "\n",
    "# create numerical index for each attr in cats\n",
    "create_cats_idx(adata, cats)\n",
    "\n",
    "# save adata\n",
    "# adata.write_h5ad('data/heart_preprocessed1200.h5ad')\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43604ca5-de54-4225-8a26-f1081a04356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = adata.to_df()\n",
    "# print(df)\n",
    "# df_subset = df.iloc[:, -200:]\n",
    "# print(df_subset)\n",
    "# print(df_subset[df_subset.ge(2).any(axis=1)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dfb58c-a2ae-4c80-a575-cdf914ebd674",
   "metadata": {},
   "source": [
    "# train model: dis2p(n_cf=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e94f01b8-3ff9-4710-a537-59058524f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "583aaf20-11d2-4e68-9ff8-8e3b8296fe4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1699537993.313799   24397 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 18641 × 1200\n",
      "    obs: 'NRP', 'age_group', 'cell_source', 'cell_type', 'donor', 'gender', 'n_counts', 'n_genes', 'percent_mito', 'percent_ribo', 'region', 'sample', 'scrublet_score', 'source', 'type', 'version', 'cell_states', 'Used', 'cell_type_idx', 'cell_source_idx', 'gender_idx', 'region_idx', '_scvi_batch', '_scvi_labels'\n",
      "    var: 'gene_ids-Harvard-Nuclei', 'feature_types-Harvard-Nuclei', 'gene_ids-Sanger-Nuclei', 'feature_types-Sanger-Nuclei', 'gene_ids-Sanger-Cells', 'feature_types-Sanger-Cells', 'gene_ids-Sanger-CD45', 'feature_types-Sanger-CD45', 'n_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
      "    uns: 'cell_type_colors', 'log1p', 'hvg', '_scvi_uuid', '_scvi_manager_uuid'\n",
      "    obsm: '_scvi_extra_categorical_covs'\n",
      "    layers: 'counts'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "debug4\n",
      "n_cats_per_cov is (11, 4, 2, 6)\n",
      "debug4\n",
      "debug5\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/jupyter/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py:321: RuntimeWarning: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 0/50 [00:00<?, ?it/s]the p size is torch.Size([4, 200])\n",
      "the x size is torch.Size([4, 200])\n",
      "the p size is torch.Size([4, 200])\n",
      "the x size is torch.Size([4, 200])\n",
      "the p size is torch.Size([4, 200])\n",
      "the x size is torch.Size([4, 200])\n",
      "the p size is torch.Size([4, 200])\n",
      "the x size is torch.Size([4, 200])\n",
      "the p size is torch.Size([4, 200])\n",
      "the x size is torch.Size([4, 200])\n",
      "ATAC reconstruction loss X' \n",
      "idx + 1 = 1\n",
      "x_ = tensor([[ 0.,  0.,  1.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  1.,  0.,  2.,  0.,  0.,  3.,  0.,  1.,  0.,  3.,\n",
      "          0.,  6.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  4.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  0.,  0.,  4.,  0.,  0.,\n",
      "          4.,  0.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  5.,\n",
      "          3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  2.,\n",
      "          0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,\n",
      "          0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  5.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0., 30., 68., 89.,\n",
      "         76., 41., 40., 53.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,\n",
      "          1.,  0.,  0.,  1.,  3.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  8.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  4.,\n",
      "          1.,  0.,  2.,  2.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,\n",
      "          3.,  1.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  3.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  3.,  0.,\n",
      "          0.,  0.,  1.,  1.]], device='cuda:0')\n",
      "cat_cov_ = tensor([[10.,  1.,  0.,  4.],\n",
      "        [ 2.,  0.,  0.,  1.],\n",
      "        [ 3.,  0.,  1.,  2.],\n",
      "        [ 8.,  0.,  0.,  2.]], device='cuda:0')\n",
      "detached x\n",
      "torch.split \n",
      "detached z\n",
      "dec_cats \n",
      "x_decoder \n",
      "x_decoder 2\n",
      "idx + 1 = 2\n",
      "x_ = tensor([[0.3555, 0.5858, 0.5913, 0.6765, 0.5623, 0.3866, 0.5519, 0.4928, 0.5712,\n",
      "         0.4972, 0.5852, 0.4010, 0.5250, 0.5105, 0.4500, 0.5512, 0.3660, 0.4522,\n",
      "         0.4121, 0.3983, 0.6814, 0.5163, 0.5784, 0.4493, 0.4238, 0.4050, 0.3606,\n",
      "         0.3687, 0.5118, 0.5201, 0.5044, 0.5764, 0.4754, 0.4090, 0.5377, 0.5875,\n",
      "         0.5451, 0.5503, 0.4573, 0.3526, 0.4181, 0.6369, 0.4377, 0.5468, 0.4779,\n",
      "         0.4653, 0.5597, 0.5148, 0.5000, 0.7305, 0.5681, 0.5127, 0.6410, 0.4756,\n",
      "         0.4322, 0.2839, 0.4935, 0.3405, 0.5018, 0.4017, 0.3595, 0.5586, 0.4860,\n",
      "         0.5655, 0.4769, 0.4288, 0.3990, 0.5059, 0.5862, 0.5672, 0.6144, 0.7965,\n",
      "         0.4838, 0.6017, 0.4892, 0.5489, 0.5043, 0.6870, 0.4620, 0.6691, 0.5946,\n",
      "         0.5209, 0.4159, 0.4313, 0.6174, 0.6636, 0.5037, 0.4845, 0.4390, 0.5576,\n",
      "         0.4306, 0.4569, 0.2865, 0.5152, 0.3602, 0.4333, 0.4881, 0.5627, 0.3357,\n",
      "         0.4716, 0.5523, 0.5267, 0.5081, 0.5262, 0.4655, 0.6100, 0.6173, 0.3746,\n",
      "         0.4246, 0.5024, 0.6519, 0.2610, 0.5190, 0.4768, 0.3534, 0.7023, 0.4753,\n",
      "         0.4595, 0.4485, 0.5677, 0.2933, 0.3919, 0.6008, 0.4776, 0.5794, 0.5412,\n",
      "         0.6603, 0.4180, 0.3630, 0.4074, 0.4777, 0.4533, 0.5739, 0.3423, 0.4771,\n",
      "         0.4582, 0.4329, 0.5942, 0.4308, 0.2365, 0.5255, 0.4070, 0.6058, 0.5304,\n",
      "         0.4810, 0.4045, 0.3631, 0.5307, 0.4900, 0.2755, 0.6801, 0.4818, 0.6500,\n",
      "         0.7261, 0.5742, 0.4366, 0.4885, 0.4328, 0.5100, 0.5651, 0.5079, 0.4201,\n",
      "         0.6069, 0.3764, 0.5353, 0.4262, 0.3920, 0.6960, 0.5595, 0.2892, 0.3882,\n",
      "         0.5622, 0.3136, 0.5042, 0.4516, 0.5809, 0.4612, 0.4921, 0.4402, 0.4201,\n",
      "         0.4297, 0.4925, 0.5180, 0.3013, 0.3921, 0.4387, 0.6341, 0.4613, 0.4493,\n",
      "         0.3392, 0.5706, 0.5043, 0.7085, 0.5112, 0.6384, 0.5976, 0.4524, 0.3889,\n",
      "         0.5715, 0.5277],\n",
      "        [0.5046, 0.5972, 0.6201, 0.4818, 0.5195, 0.5228, 0.5463, 0.3694, 0.4709,\n",
      "         0.5468, 0.4011, 0.5921, 0.4132, 0.4512, 0.4179, 0.5287, 0.6221, 0.4933,\n",
      "         0.4539, 0.4517, 0.5868, 0.3051, 0.5792, 0.4839, 0.4894, 0.6141, 0.6078,\n",
      "         0.4848, 0.5323, 0.5524, 0.4685, 0.5591, 0.4580, 0.6337, 0.5044, 0.5011,\n",
      "         0.4510, 0.5079, 0.4923, 0.3766, 0.5251, 0.5218, 0.6123, 0.5828, 0.4684,\n",
      "         0.4409, 0.5410, 0.6740, 0.4335, 0.4967, 0.4580, 0.4964, 0.4190, 0.4358,\n",
      "         0.4348, 0.3351, 0.5949, 0.5402, 0.3465, 0.4989, 0.5275, 0.4487, 0.5149,\n",
      "         0.6030, 0.5371, 0.4180, 0.4672, 0.6164, 0.5815, 0.4758, 0.4283, 0.4451,\n",
      "         0.4842, 0.5026, 0.5300, 0.5091, 0.4918, 0.5566, 0.3722, 0.6688, 0.3938,\n",
      "         0.5681, 0.5630, 0.4601, 0.4387, 0.4787, 0.5098, 0.5770, 0.5145, 0.3854,\n",
      "         0.4329, 0.5009, 0.4199, 0.5541, 0.4950, 0.3221, 0.6115, 0.5622, 0.5079,\n",
      "         0.4197, 0.3707, 0.6657, 0.5728, 0.3906, 0.5673, 0.3856, 0.7893, 0.5247,\n",
      "         0.4605, 0.5134, 0.5036, 0.4279, 0.4406, 0.5231, 0.3629, 0.5765, 0.4184,\n",
      "         0.4783, 0.6213, 0.4451, 0.5334, 0.4621, 0.4017, 0.5988, 0.5634, 0.5479,\n",
      "         0.4209, 0.5678, 0.3974, 0.5510, 0.4823, 0.4351, 0.4441, 0.5656, 0.5102,\n",
      "         0.4296, 0.4171, 0.5121, 0.5084, 0.4753, 0.5512, 0.3693, 0.5512, 0.5647,\n",
      "         0.6036, 0.4323, 0.5755, 0.5066, 0.4491, 0.4405, 0.4360, 0.4087, 0.5612,\n",
      "         0.4734, 0.3675, 0.6113, 0.4391, 0.5733, 0.3931, 0.4447, 0.5918, 0.6192,\n",
      "         0.4251, 0.5245, 0.3298, 0.5028, 0.6053, 0.5730, 0.5342, 0.4869, 0.6163,\n",
      "         0.4735, 0.4001, 0.5253, 0.3660, 0.7086, 0.5484, 0.4589, 0.6559, 0.3777,\n",
      "         0.5840, 0.5450, 0.4954, 0.5174, 0.3332, 0.3519, 0.5638, 0.5199, 0.4641,\n",
      "         0.5223, 0.4449, 0.3957, 0.5458, 0.4255, 0.5683, 0.5730, 0.5283, 0.4115,\n",
      "         0.5146, 0.5468],\n",
      "        [0.4856, 0.3666, 0.5400, 0.4947, 0.3952, 0.5509, 0.4789, 0.4538, 0.5408,\n",
      "         0.6667, 0.6191, 0.4725, 0.4743, 0.5120, 0.3857, 0.7055, 0.3395, 0.7248,\n",
      "         0.3100, 0.2958, 0.5477, 0.4120, 0.6093, 0.4573, 0.3161, 0.5900, 0.4810,\n",
      "         0.5475, 0.3729, 0.3353, 0.4444, 0.4440, 0.3818, 0.3636, 0.6605, 0.4917,\n",
      "         0.5045, 0.4929, 0.5726, 0.5277, 0.4766, 0.5414, 0.5035, 0.6905, 0.4526,\n",
      "         0.5494, 0.4640, 0.5569, 0.5298, 0.5307, 0.4457, 0.5381, 0.4126, 0.5291,\n",
      "         0.4677, 0.4736, 0.4323, 0.4534, 0.3731, 0.4840, 0.4257, 0.5869, 0.4024,\n",
      "         0.4776, 0.5391, 0.3483, 0.3956, 0.3955, 0.5909, 0.5176, 0.4606, 0.4236,\n",
      "         0.3516, 0.4845, 0.6227, 0.4163, 0.3239, 0.6048, 0.3670, 0.5790, 0.5790,\n",
      "         0.4228, 0.5808, 0.2816, 0.5838, 0.4392, 0.4159, 0.4958, 0.4710, 0.4710,\n",
      "         0.5847, 0.5649, 0.3077, 0.3284, 0.4836, 0.3007, 0.5278, 0.4171, 0.3276,\n",
      "         0.3856, 0.5603, 0.7276, 0.5101, 0.5419, 0.4604, 0.3707, 0.6661, 0.4995,\n",
      "         0.5735, 0.3886, 0.4742, 0.4300, 0.5346, 0.5449, 0.5380, 0.5907, 0.5415,\n",
      "         0.7044, 0.5410, 0.5201, 0.5739, 0.5189, 0.5338, 0.4038, 0.6364, 0.6673,\n",
      "         0.4235, 0.5329, 0.4729, 0.4390, 0.4101, 0.5864, 0.7043, 0.4742, 0.4554,\n",
      "         0.4710, 0.4766, 0.5394, 0.5192, 0.3918, 0.5840, 0.4881, 0.7127, 0.5074,\n",
      "         0.4904, 0.5214, 0.4574, 0.5080, 0.5159, 0.3628, 0.6545, 0.4377, 0.6541,\n",
      "         0.4550, 0.5733, 0.6964, 0.3058, 0.4855, 0.7195, 0.4279, 0.4958, 0.6640,\n",
      "         0.4886, 0.4196, 0.5999, 0.4957, 0.5125, 0.5840, 0.4730, 0.4343, 0.4411,\n",
      "         0.4805, 0.6578, 0.4131, 0.4267, 0.7352, 0.4180, 0.2854, 0.4727, 0.4867,\n",
      "         0.4047, 0.4729, 0.6097, 0.3816, 0.6650, 0.5053, 0.3708, 0.5099, 0.5156,\n",
      "         0.3857, 0.3801, 0.5916, 0.7449, 0.5876, 0.4493, 0.5105, 0.4601, 0.3991,\n",
      "         0.5662, 0.5356],\n",
      "        [0.4514, 0.5838, 0.5986, 0.4795, 0.5498, 0.5434, 0.5124, 0.5643, 0.4872,\n",
      "         0.6754, 0.3747, 0.4938, 0.3974, 0.4974, 0.6328, 0.2950, 0.2896, 0.4475,\n",
      "         0.4895, 0.4140, 0.3987, 0.5608, 0.5614, 0.4410, 0.4659, 0.3310, 0.4596,\n",
      "         0.3123, 0.5083, 0.4504, 0.5300, 0.5334, 0.5096, 0.7090, 0.6298, 0.6088,\n",
      "         0.1948, 0.2830, 0.4726, 0.5458, 0.6159, 0.5616, 0.4655, 0.5728, 0.4196,\n",
      "         0.4957, 0.4900, 0.6793, 0.5650, 0.5886, 0.5625, 0.4352, 0.5743, 0.5514,\n",
      "         0.3565, 0.5264, 0.5712, 0.3975, 0.4787, 0.5259, 0.6055, 0.6004, 0.4477,\n",
      "         0.4209, 0.5461, 0.5178, 0.5574, 0.3531, 0.4068, 0.5073, 0.5264, 0.6304,\n",
      "         0.5058, 0.5159, 0.6739, 0.3823, 0.4661, 0.5954, 0.4378, 0.4480, 0.4180,\n",
      "         0.3458, 0.5534, 0.5226, 0.7007, 0.4514, 0.3578, 0.5587, 0.7164, 0.5475,\n",
      "         0.5180, 0.5402, 0.4883, 0.4738, 0.3844, 0.4603, 0.6007, 0.6269, 0.5155,\n",
      "         0.3960, 0.5090, 0.3581, 0.4914, 0.4446, 0.4690, 0.5217, 0.5752, 0.4394,\n",
      "         0.4166, 0.5447, 0.4861, 0.7504, 0.5476, 0.3210, 0.4474, 0.5788, 0.4623,\n",
      "         0.3679, 0.4151, 0.5403, 0.4439, 0.5598, 0.6869, 0.5068, 0.4567, 0.5443,\n",
      "         0.5565, 0.3097, 0.4473, 0.3734, 0.6965, 0.5807, 0.4456, 0.3781, 0.4668,\n",
      "         0.6008, 0.2855, 0.5063, 0.5933, 0.4458, 0.4335, 0.6712, 0.4792, 0.5069,\n",
      "         0.6054, 0.6084, 0.3914, 0.4224, 0.5931, 0.3871, 0.5684, 0.5712, 0.4359,\n",
      "         0.5813, 0.4015, 0.5704, 0.5945, 0.3988, 0.6833, 0.5775, 0.5937, 0.4043,\n",
      "         0.4402, 0.4674, 0.5464, 0.3882, 0.5022, 0.4714, 0.4124, 0.3612, 0.5134,\n",
      "         0.1786, 0.5476, 0.4017, 0.2942, 0.6050, 0.4862, 0.3375, 0.5269, 0.4093,\n",
      "         0.6135, 0.5815, 0.4826, 0.4825, 0.3830, 0.6155, 0.5195, 0.5531, 0.4731,\n",
      "         0.5471, 0.6246, 0.5127, 0.5324, 0.4963, 0.5409, 0.4433, 0.3837, 0.4127,\n",
      "         0.6326, 0.6384]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "cat_cov_ = tensor([[10.,  0.,  0.,  4.],\n",
      "        [ 2.,  1.,  0.,  1.],\n",
      "        [ 3.,  0.,  1.,  2.],\n",
      "        [ 8.,  0.,  0.,  2.]], device='cuda:0')\n",
      "detached x\n",
      "torch.split \n",
      "detached z\n",
      "dec_cats \n",
      "x_decoder \n",
      "x_decoder 2\n",
      "idx + 1 = 4\n",
      "x_ = tensor([[0.6574, 0.3729, 0.6422, 0.3347, 0.5459, 0.4416, 0.6363, 0.4043, 0.5710,\n",
      "         0.5140, 0.6012, 0.4141, 0.4478, 0.5201, 0.6096, 0.4301, 0.4427, 0.5075,\n",
      "         0.5848, 0.5516, 0.4967, 0.6422, 0.6296, 0.4032, 0.4872, 0.4465, 0.4316,\n",
      "         0.5360, 0.4400, 0.3170, 0.4494, 0.4427, 0.5210, 0.6432, 0.6054, 0.3684,\n",
      "         0.4910, 0.4557, 0.5068, 0.4000, 0.3698, 0.5579, 0.5525, 0.6101, 0.5013,\n",
      "         0.5572, 0.6105, 0.5676, 0.6995, 0.3590, 0.2721, 0.4894, 0.5859, 0.6789,\n",
      "         0.5344, 0.6269, 0.4521, 0.4395, 0.3735, 0.4449, 0.5412, 0.5325, 0.3898,\n",
      "         0.4238, 0.4930, 0.5447, 0.5376, 0.4215, 0.4911, 0.3403, 0.6245, 0.5000,\n",
      "         0.5359, 0.2674, 0.4267, 0.4999, 0.5106, 0.4794, 0.4372, 0.5379, 0.6027,\n",
      "         0.5110, 0.5973, 0.4340, 0.3864, 0.4558, 0.4659, 0.4970, 0.5649, 0.5170,\n",
      "         0.4922, 0.5018, 0.6623, 0.5121, 0.3174, 0.4045, 0.5243, 0.6234, 0.5923,\n",
      "         0.3505, 0.3265, 0.3856, 0.6529, 0.5184, 0.5668, 0.6849, 0.5046, 0.4870,\n",
      "         0.5701, 0.5674, 0.3334, 0.5470, 0.5483, 0.4045, 0.5532, 0.6159, 0.4247,\n",
      "         0.5104, 0.4193, 0.4315, 0.4938, 0.3880, 0.4800, 0.6907, 0.6706, 0.4972,\n",
      "         0.4246, 0.5584, 0.5173, 0.5267, 0.3660, 0.4536, 0.5760, 0.5714, 0.4552,\n",
      "         0.4697, 0.4067, 0.3575, 0.4132, 0.5160, 0.5809, 0.6197, 0.5724, 0.4344,\n",
      "         0.4765, 0.5523, 0.5798, 0.4897, 0.7228, 0.4874, 0.5530, 0.3883, 0.5840,\n",
      "         0.4343, 0.5205, 0.5716, 0.5529, 0.6283, 0.5824, 0.6064, 0.6040, 0.3824,\n",
      "         0.5741, 0.4671, 0.4565, 0.5435, 0.3913, 0.4624, 0.4791, 0.4393, 0.5926,\n",
      "         0.5826, 0.4865, 0.4146, 0.4744, 0.5708, 0.4819, 0.4628, 0.4382, 0.4103,\n",
      "         0.4656, 0.4973, 0.5554, 0.6007, 0.3663, 0.5550, 0.6022, 0.3805, 0.3002,\n",
      "         0.5662, 0.4939, 0.5421, 0.5562, 0.4320, 0.3804, 0.5847, 0.4752, 0.3342,\n",
      "         0.4816, 0.3861],\n",
      "        [0.4844, 0.5301, 0.5687, 0.5203, 0.5605, 0.6440, 0.5215, 0.4078, 0.7152,\n",
      "         0.4093, 0.6334, 0.4927, 0.4258, 0.5300, 0.3542, 0.5095, 0.3475, 0.5724,\n",
      "         0.4089, 0.5992, 0.4249, 0.5373, 0.4898, 0.4647, 0.5286, 0.6458, 0.4876,\n",
      "         0.5832, 0.5212, 0.5226, 0.4109, 0.3253, 0.4898, 0.3808, 0.5274, 0.4434,\n",
      "         0.4280, 0.5399, 0.5888, 0.4587, 0.6203, 0.6413, 0.5686, 0.4757, 0.6334,\n",
      "         0.6566, 0.4984, 0.4548, 0.4904, 0.5309, 0.4111, 0.4820, 0.4688, 0.4924,\n",
      "         0.5187, 0.3459, 0.5092, 0.3552, 0.5855, 0.5522, 0.4248, 0.4550, 0.4817,\n",
      "         0.5054, 0.4260, 0.4540, 0.3718, 0.6479, 0.4496, 0.5386, 0.4194, 0.5348,\n",
      "         0.4929, 0.3336, 0.4150, 0.5157, 0.5057, 0.5523, 0.4458, 0.5311, 0.5885,\n",
      "         0.4606, 0.4315, 0.3924, 0.4639, 0.6293, 0.4050, 0.4747, 0.5844, 0.6134,\n",
      "         0.5658, 0.4584, 0.6185, 0.3610, 0.5094, 0.5823, 0.4064, 0.5421, 0.5158,\n",
      "         0.4562, 0.3452, 0.3788, 0.6282, 0.4938, 0.5002, 0.4722, 0.5199, 0.6205,\n",
      "         0.5836, 0.4691, 0.3064, 0.4259, 0.5482, 0.3748, 0.4232, 0.5613, 0.4342,\n",
      "         0.6239, 0.5581, 0.5263, 0.3531, 0.5491, 0.5006, 0.6156, 0.4458, 0.3738,\n",
      "         0.3861, 0.5521, 0.4854, 0.5532, 0.3949, 0.5465, 0.5924, 0.4715, 0.6394,\n",
      "         0.5951, 0.5942, 0.3878, 0.3850, 0.5276, 0.5410, 0.4221, 0.6462, 0.4714,\n",
      "         0.5319, 0.4971, 0.4011, 0.5913, 0.6137, 0.5385, 0.5114, 0.5627, 0.6537,\n",
      "         0.4962, 0.5894, 0.6105, 0.5697, 0.6054, 0.4428, 0.6338, 0.4477, 0.5502,\n",
      "         0.5321, 0.4784, 0.6160, 0.4973, 0.4517, 0.6620, 0.4918, 0.5431, 0.6835,\n",
      "         0.5614, 0.4454, 0.3383, 0.5609, 0.5511, 0.5294, 0.4651, 0.5466, 0.3942,\n",
      "         0.4034, 0.5867, 0.5002, 0.6449, 0.4888, 0.5058, 0.5214, 0.5109, 0.4979,\n",
      "         0.3904, 0.5510, 0.5785, 0.4502, 0.4351, 0.5398, 0.5173, 0.7362, 0.3649,\n",
      "         0.5538, 0.5074],\n",
      "        [0.5302, 0.4032, 0.6033, 0.6042, 0.5554, 0.5512, 0.3566, 0.4815, 0.6162,\n",
      "         0.3886, 0.4883, 0.5875, 0.3298, 0.3606, 0.5205, 0.4777, 0.3823, 0.3824,\n",
      "         0.4911, 0.5683, 0.4470, 0.6667, 0.4662, 0.5444, 0.4752, 0.4954, 0.3603,\n",
      "         0.3856, 0.6189, 0.5568, 0.5873, 0.3451, 0.5496, 0.5470, 0.4393, 0.4233,\n",
      "         0.5577, 0.5882, 0.4216, 0.5002, 0.5156, 0.6850, 0.5217, 0.5944, 0.4440,\n",
      "         0.6175, 0.4241, 0.3027, 0.4785, 0.4939, 0.4911, 0.5141, 0.4826, 0.5354,\n",
      "         0.5351, 0.4075, 0.6034, 0.3838, 0.3689, 0.6405, 0.4716, 0.5112, 0.5376,\n",
      "         0.6507, 0.4447, 0.3493, 0.4572, 0.5171, 0.6210, 0.5194, 0.5990, 0.4688,\n",
      "         0.4303, 0.3083, 0.5290, 0.4994, 0.6225, 0.6029, 0.4510, 0.5073, 0.4654,\n",
      "         0.6772, 0.3887, 0.4980, 0.4401, 0.5337, 0.3645, 0.5418, 0.7134, 0.3989,\n",
      "         0.6003, 0.4036, 0.5766, 0.5622, 0.4672, 0.5860, 0.4965, 0.4832, 0.3826,\n",
      "         0.5624, 0.4967, 0.4054, 0.4856, 0.4619, 0.4757, 0.5111, 0.3955, 0.5555,\n",
      "         0.5300, 0.5759, 0.4995, 0.6803, 0.5294, 0.5966, 0.4042, 0.5009, 0.4103,\n",
      "         0.6324, 0.4867, 0.6238, 0.5301, 0.4725, 0.3960, 0.4850, 0.6608, 0.4491,\n",
      "         0.4257, 0.3287, 0.5383, 0.5673, 0.5486, 0.5971, 0.5573, 0.5330, 0.3881,\n",
      "         0.5332, 0.5524, 0.4150, 0.6456, 0.6988, 0.6211, 0.3648, 0.4093, 0.3530,\n",
      "         0.3918, 0.5346, 0.6028, 0.5960, 0.5490, 0.4975, 0.4701, 0.5478, 0.3778,\n",
      "         0.4819, 0.4656, 0.5268, 0.5604, 0.4050, 0.5096, 0.5153, 0.4966, 0.4668,\n",
      "         0.5711, 0.4237, 0.4823, 0.5724, 0.3564, 0.5210, 0.7041, 0.5631, 0.5976,\n",
      "         0.6257, 0.6146, 0.4342, 0.5392, 0.6930, 0.4384, 0.5991, 0.3604, 0.3781,\n",
      "         0.5023, 0.4730, 0.6299, 0.4856, 0.3181, 0.5427, 0.4692, 0.5469, 0.5682,\n",
      "         0.3038, 0.5031, 0.4819, 0.5862, 0.5803, 0.5764, 0.6384, 0.5447, 0.5363,\n",
      "         0.4806, 0.4658],\n",
      "        [0.6298, 0.5281, 0.5070, 0.5964, 0.3709, 0.4956, 0.5346, 0.6120, 0.5623,\n",
      "         0.4073, 0.4398, 0.5304, 0.3233, 0.3183, 0.3212, 0.6610, 0.5347, 0.2906,\n",
      "         0.8513, 0.4924, 0.4044, 0.3216, 0.5300, 0.4600, 0.2380, 0.4379, 0.4715,\n",
      "         0.4726, 0.3871, 0.5524, 0.5195, 0.4486, 0.5521, 0.6060, 0.4201, 0.6409,\n",
      "         0.4436, 0.4894, 0.5284, 0.2583, 0.4304, 0.4974, 0.5494, 0.5057, 0.5757,\n",
      "         0.6312, 0.4946, 0.5186, 0.4703, 0.5177, 0.4681, 0.4039, 0.5304, 0.5180,\n",
      "         0.5038, 0.4250, 0.6619, 0.5496, 0.4626, 0.5268, 0.5635, 0.3579, 0.5944,\n",
      "         0.4392, 0.3693, 0.3651, 0.4732, 0.5337, 0.4063, 0.3713, 0.6475, 0.4229,\n",
      "         0.5281, 0.3762, 0.5967, 0.5604, 0.4379, 0.5157, 0.4399, 0.4560, 0.5236,\n",
      "         0.4508, 0.5050, 0.3980, 0.1967, 0.5294, 0.4325, 0.4334, 0.7977, 0.3018,\n",
      "         0.3232, 0.4889, 0.5672, 0.4804, 0.5887, 0.3633, 0.4736, 0.6626, 0.4190,\n",
      "         0.6677, 0.2611, 0.3222, 0.3359, 0.4104, 0.4324, 0.5888, 0.3516, 0.5876,\n",
      "         0.6839, 0.4526, 0.4203, 0.7090, 0.6465, 0.3884, 0.6116, 0.5193, 0.5435,\n",
      "         0.6360, 0.5014, 0.5247, 0.5463, 0.4782, 0.5663, 0.4909, 0.5994, 0.5469,\n",
      "         0.6247, 0.5526, 0.4005, 0.5088, 0.2434, 0.4764, 0.5332, 0.7461, 0.4920,\n",
      "         0.5370, 0.4927, 0.4894, 0.4538, 0.5051, 0.4572, 0.6059, 0.5646, 0.6152,\n",
      "         0.4733, 0.3938, 0.5618, 0.4250, 0.4163, 0.5756, 0.4433, 0.6634, 0.5976,\n",
      "         0.3851, 0.7081, 0.5036, 0.6100, 0.4652, 0.3854, 0.6223, 0.6012, 0.4100,\n",
      "         0.6214, 0.6655, 0.4818, 0.3435, 0.4096, 0.6580, 0.6363, 0.5699, 0.5148,\n",
      "         0.6430, 0.3195, 0.4586, 0.5570, 0.4244, 0.6262, 0.3248, 0.5647, 0.5234,\n",
      "         0.4045, 0.5671, 0.5034, 0.6231, 0.3206, 0.4847, 0.7110, 0.4636, 0.3890,\n",
      "         0.4886, 0.3767, 0.5228, 0.3652, 0.3401, 0.6809, 0.6199, 0.4741, 0.3000,\n",
      "         0.5358, 0.5785]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "cat_cov_ = tensor([[10.,  0.,  0.,  2.],\n",
      "        [ 2.,  1.,  0.,  4.],\n",
      "        [ 3.,  0.,  1.,  1.],\n",
      "        [ 8.,  0.,  0.,  2.]], device='cuda:0')\n",
      "detached x\n",
      "torch.split \n",
      "detached z\n",
      "dec_cats \n",
      "x_decoder \n",
      "x_decoder 2\n",
      "idx + 1 = 3\n",
      "x_ = tensor([[0.5026, 0.4100, 0.5966, 0.4859, 0.7249, 0.5017, 0.5582, 0.5621, 0.4169,\n",
      "         0.5738, 0.3534, 0.4986, 0.5309, 0.3722, 0.6237, 0.4322, 0.4784, 0.4635,\n",
      "         0.4396, 0.4910, 0.5762, 0.7371, 0.6989, 0.4678, 0.4097, 0.5350, 0.4818,\n",
      "         0.6066, 0.6115, 0.6368, 0.5120, 0.6401, 0.6260, 0.5768, 0.4820, 0.4546,\n",
      "         0.5629, 0.6636, 0.5720, 0.4979, 0.4600, 0.4026, 0.5861, 0.4112, 0.4942,\n",
      "         0.5513, 0.4263, 0.5948, 0.5398, 0.5476, 0.6037, 0.4900, 0.5155, 0.4199,\n",
      "         0.4732, 0.5494, 0.5070, 0.5291, 0.6598, 0.4085, 0.4688, 0.4212, 0.4739,\n",
      "         0.5453, 0.6036, 0.4304, 0.4342, 0.5354, 0.4406, 0.5322, 0.6651, 0.6091,\n",
      "         0.6248, 0.3835, 0.5153, 0.4661, 0.4548, 0.3888, 0.5288, 0.4449, 0.5047,\n",
      "         0.4704, 0.5135, 0.4965, 0.5560, 0.3385, 0.3976, 0.5683, 0.4367, 0.5002,\n",
      "         0.3871, 0.4342, 0.4514, 0.4317, 0.5249, 0.5966, 0.5639, 0.4983, 0.5387,\n",
      "         0.5877, 0.4850, 0.5293, 0.6634, 0.4194, 0.6212, 0.4417, 0.5124, 0.4555,\n",
      "         0.5838, 0.6057, 0.4854, 0.5323, 0.3807, 0.4925, 0.5346, 0.6102, 0.5098,\n",
      "         0.5653, 0.5302, 0.6643, 0.3613, 0.3852, 0.4716, 0.4078, 0.4378, 0.5323,\n",
      "         0.4979, 0.4877, 0.5792, 0.4376, 0.5480, 0.5383, 0.4195, 0.3698, 0.5242,\n",
      "         0.3322, 0.5207, 0.4423, 0.5192, 0.6832, 0.5388, 0.4886, 0.5658, 0.5707,\n",
      "         0.6530, 0.5769, 0.5364, 0.5393, 0.5976, 0.4542, 0.5482, 0.5959, 0.4222,\n",
      "         0.5360, 0.3399, 0.3353, 0.5309, 0.4395, 0.5453, 0.4678, 0.4286, 0.5366,\n",
      "         0.5482, 0.5853, 0.5501, 0.5441, 0.5446, 0.5552, 0.5443, 0.3616, 0.3932,\n",
      "         0.5939, 0.4649, 0.4322, 0.4547, 0.5511, 0.4783, 0.4213, 0.6088, 0.6602,\n",
      "         0.5155, 0.3750, 0.4759, 0.6121, 0.5580, 0.3379, 0.4173, 0.4627, 0.4462,\n",
      "         0.5030, 0.4579, 0.5388, 0.3847, 0.5549, 0.4985, 0.3664, 0.3127, 0.3649,\n",
      "         0.7097, 0.4005],\n",
      "        [0.4257, 0.2368, 0.4173, 0.6064, 0.6619, 0.5730, 0.3605, 0.5458, 0.5060,\n",
      "         0.5218, 0.3966, 0.5273, 0.5017, 0.6927, 0.4662, 0.6064, 0.3361, 0.4123,\n",
      "         0.5432, 0.5104, 0.4019, 0.4336, 0.5594, 0.4729, 0.4389, 0.5445, 0.3955,\n",
      "         0.4934, 0.5812, 0.4990, 0.7172, 0.4317, 0.6230, 0.3732, 0.5081, 0.5306,\n",
      "         0.4444, 0.5167, 0.5091, 0.6608, 0.4516, 0.6333, 0.4701, 0.3108, 0.4938,\n",
      "         0.6065, 0.4030, 0.6846, 0.5625, 0.7636, 0.6450, 0.5774, 0.6320, 0.3315,\n",
      "         0.5273, 0.6760, 0.4687, 0.6085, 0.6216, 0.7304, 0.3195, 0.7061, 0.3731,\n",
      "         0.6377, 0.4734, 0.2976, 0.3808, 0.4570, 0.4719, 0.4923, 0.6320, 0.7709,\n",
      "         0.4270, 0.6777, 0.4987, 0.5978, 0.3351, 0.4562, 0.6295, 0.6690, 0.4890,\n",
      "         0.3805, 0.4435, 0.5532, 0.5543, 0.6934, 0.4921, 0.5310, 0.5022, 0.6062,\n",
      "         0.5846, 0.4106, 0.3909, 0.4117, 0.5020, 0.7335, 0.6011, 0.3346, 0.3736,\n",
      "         0.4115, 0.2980, 0.6426, 0.4869, 0.3902, 0.4003, 0.3928, 0.5213, 0.4332,\n",
      "         0.5504, 0.4116, 0.2301, 0.5656, 0.4182, 0.5049, 0.4990, 0.5206, 0.6249,\n",
      "         0.3046, 0.6396, 0.5955, 0.3983, 0.5075, 0.5237, 0.4817, 0.3985, 0.5540,\n",
      "         0.3681, 0.4221, 0.3889, 0.5827, 0.3692, 0.5730, 0.6099, 0.4945, 0.5139,\n",
      "         0.6547, 0.5069, 0.5257, 0.3342, 0.5112, 0.6756, 0.6754, 0.5893, 0.6133,\n",
      "         0.6392, 0.4790, 0.5290, 0.5194, 0.4154, 0.4204, 0.7193, 0.6023, 0.3667,\n",
      "         0.5498, 0.5286, 0.4611, 0.4419, 0.5615, 0.4187, 0.7059, 0.7154, 0.5521,\n",
      "         0.3948, 0.4968, 0.4660, 0.3995, 0.5096, 0.5386, 0.5067, 0.5870, 0.5023,\n",
      "         0.5240, 0.5814, 0.4916, 0.3545, 0.4957, 0.3967, 0.3943, 0.7160, 0.5467,\n",
      "         0.6998, 0.5829, 0.4781, 0.4018, 0.7291, 0.4318, 0.6344, 0.6101, 0.6233,\n",
      "         0.3735, 0.4172, 0.5924, 0.5323, 0.5595, 0.5576, 0.5084, 0.4603, 0.5002,\n",
      "         0.5742, 0.6014],\n",
      "        [0.5378, 0.4817, 0.6569, 0.6024, 0.6244, 0.5277, 0.4211, 0.5721, 0.3809,\n",
      "         0.4754, 0.4742, 0.6500, 0.6226, 0.5376, 0.4537, 0.4201, 0.5535, 0.5319,\n",
      "         0.5908, 0.4914, 0.4962, 0.3623, 0.5465, 0.5141, 0.5785, 0.5764, 0.5785,\n",
      "         0.4831, 0.5892, 0.5718, 0.5302, 0.5737, 0.8062, 0.6206, 0.4566, 0.4303,\n",
      "         0.7017, 0.5655, 0.5291, 0.5382, 0.4404, 0.3655, 0.4830, 0.4026, 0.4024,\n",
      "         0.3934, 0.4840, 0.6592, 0.5368, 0.5869, 0.3807, 0.5380, 0.6102, 0.5068,\n",
      "         0.5731, 0.4511, 0.6605, 0.6824, 0.4361, 0.4144, 0.4669, 0.5264, 0.3641,\n",
      "         0.5480, 0.5246, 0.4721, 0.6537, 0.5656, 0.3576, 0.5399, 0.3959, 0.6340,\n",
      "         0.3555, 0.4671, 0.5918, 0.6263, 0.3683, 0.3784, 0.4524, 0.6787, 0.5329,\n",
      "         0.5079, 0.4433, 0.4518, 0.5716, 0.3676, 0.5617, 0.4417, 0.4704, 0.4446,\n",
      "         0.6420, 0.3987, 0.4210, 0.4908, 0.6348, 0.6358, 0.5607, 0.6547, 0.5084,\n",
      "         0.6220, 0.3283, 0.4082, 0.3908, 0.4438, 0.4442, 0.6554, 0.4938, 0.6687,\n",
      "         0.6708, 0.6228, 0.5677, 0.5802, 0.5450, 0.5250, 0.4589, 0.3307, 0.4883,\n",
      "         0.4157, 0.6050, 0.4456, 0.4478, 0.4316, 0.5172, 0.5737, 0.4880, 0.5678,\n",
      "         0.5848, 0.6286, 0.5089, 0.5744, 0.3626, 0.5708, 0.4223, 0.3811, 0.4672,\n",
      "         0.3675, 0.5098, 0.5214, 0.5391, 0.4215, 0.6531, 0.6395, 0.5618, 0.5266,\n",
      "         0.5355, 0.5470, 0.5312, 0.4964, 0.5881, 0.4774, 0.4552, 0.6035, 0.2740,\n",
      "         0.4262, 0.5637, 0.6555, 0.5201, 0.3342, 0.3920, 0.4274, 0.5926, 0.4554,\n",
      "         0.3472, 0.4723, 0.5378, 0.3588, 0.5302, 0.5103, 0.5997, 0.3501, 0.4567,\n",
      "         0.5670, 0.5534, 0.6239, 0.4360, 0.6739, 0.3653, 0.4129, 0.6482, 0.6032,\n",
      "         0.5456, 0.3545, 0.5134, 0.5426, 0.6571, 0.7010, 0.4790, 0.5158, 0.6291,\n",
      "         0.4425, 0.4487, 0.6056, 0.4639, 0.4728, 0.5525, 0.4763, 0.3508, 0.2691,\n",
      "         0.4981, 0.5463],\n",
      "        [0.6636, 0.6003, 0.6356, 0.6103, 0.4750, 0.5376, 0.4130, 0.3892, 0.5732,\n",
      "         0.5750, 0.3812, 0.5570, 0.5386, 0.4679, 0.6166, 0.5484, 0.5857, 0.4726,\n",
      "         0.4611, 0.5101, 0.6318, 0.5519, 0.6824, 0.4361, 0.5798, 0.5797, 0.6113,\n",
      "         0.5176, 0.5544, 0.6239, 0.6115, 0.6430, 0.4186, 0.3926, 0.4451, 0.7465,\n",
      "         0.5961, 0.6324, 0.5764, 0.4191, 0.3282, 0.5352, 0.3955, 0.6086, 0.6304,\n",
      "         0.4377, 0.3295, 0.5753, 0.5868, 0.5014, 0.4758, 0.6258, 0.4792, 0.3395,\n",
      "         0.4093, 0.4719, 0.4113, 0.3273, 0.6396, 0.3395, 0.4570, 0.5255, 0.5477,\n",
      "         0.5889, 0.6507, 0.5106, 0.5975, 0.8217, 0.3826, 0.4775, 0.7328, 0.6046,\n",
      "         0.7032, 0.4510, 0.5242, 0.4897, 0.3977, 0.3311, 0.3568, 0.4026, 0.6042,\n",
      "         0.3903, 0.6010, 0.5182, 0.3919, 0.3012, 0.3593, 0.5073, 0.3892, 0.4267,\n",
      "         0.5468, 0.3060, 0.4559, 0.3869, 0.5775, 0.4263, 0.5211, 0.4852, 0.5450,\n",
      "         0.5742, 0.2077, 0.6070, 0.7564, 0.5392, 0.5043, 0.4849, 0.4252, 0.6426,\n",
      "         0.3660, 0.5793, 0.5489, 0.5407, 0.5794, 0.4459, 0.4248, 0.6376, 0.6071,\n",
      "         0.5722, 0.5706, 0.5799, 0.5251, 0.2838, 0.2958, 0.6158, 0.3613, 0.4676,\n",
      "         0.3188, 0.4158, 0.5855, 0.3205, 0.5063, 0.4418, 0.6405, 0.4909, 0.6625,\n",
      "         0.3551, 0.5665, 0.6448, 0.5086, 0.4292, 0.4434, 0.5907, 0.6356, 0.4074,\n",
      "         0.5326, 0.6030, 0.5864, 0.6341, 0.5258, 0.5344, 0.4859, 0.5629, 0.4997,\n",
      "         0.5620, 0.3814, 0.4401, 0.4873, 0.5179, 0.6401, 0.5378, 0.6494, 0.5254,\n",
      "         0.3854, 0.4052, 0.5963, 0.2889, 0.6417, 0.5248, 0.5367, 0.5079, 0.4036,\n",
      "         0.6934, 0.4511, 0.5231, 0.3389, 0.6237, 0.4449, 0.5463, 0.4815, 0.4497,\n",
      "         0.5265, 0.3180, 0.5436, 0.5894, 0.6559, 0.3940, 0.4700, 0.5322, 0.5441,\n",
      "         0.3957, 0.4650, 0.4372, 0.5676, 0.5834, 0.4018, 0.4677, 0.2270, 0.2937,\n",
      "         0.6180, 0.3103]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "cat_cov_ = tensor([[10.,  0.,  1.,  2.],\n",
      "        [ 2.,  1.,  0.,  4.],\n",
      "        [ 3.,  0.,  0.,  1.],\n",
      "        [ 8.,  0.,  0.,  2.]], device='cuda:0')\n",
      "detached x\n",
      "torch.split \n",
      "detached z\n",
      "dec_cats \n",
      "x_decoder \n",
      "x_decoder 2\n",
      "the p size is torch.Size([4, 200])\n",
      "the x size is torch.Size([4, 200])\n",
      "ATAC KL divergence Z \n",
      "ATAC classification metrics: CE, ACC, F1 \n",
      "GEX reconstruction loss X \n",
      "GEX reconstruction loss X cf \n",
      "GEX reconstruction loss KL divergence Z \n",
      "GEX classification metrics: CE, ACC, F1 \n",
      "total loss \n",
      "reconst_loss_x_dict_acc is {'atac_0': tensor(146.4692, device='cuda:0', grad_fn=<MeanBackward0>), 'atac_1': tensor(142.3550, device='cuda:0', grad_fn=<MeanBackward0>), 'atac_2': tensor(142.9232, device='cuda:0', grad_fn=<MeanBackward0>), 'atac_3': tensor(141.4848, device='cuda:0', grad_fn=<MeanBackward0>), 'atac_4': tensor(146.3052, device='cuda:0', grad_fn=<MeanBackward0>)}\n",
      "reconst_loss_x_dict is {'x_0': tensor(446.9858, device='cuda:0', grad_fn=<NegBackward0>), 'x_1': tensor(459.2079, device='cuda:0', grad_fn=<NegBackward0>), 'x_2': tensor(452.1511, device='cuda:0', grad_fn=<NegBackward0>), 'x_3': tensor(459.2316, device='cuda:0', grad_fn=<NegBackward0>), 'x_4': tensor(460.1631, device='cuda:0', grad_fn=<NegBackward0>)}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(adata)\n\u001b[1;32m     40\u001b[0m model \u001b[38;5;241m=\u001b[39m Dis2pmVI(adata, n_genes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, n_regions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, n_layers\u001b[38;5;241m=\u001b[39mn_layers)\n\u001b[0;32m---> 41\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpre_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair/dis2pm_dev/dis2pm/dis2pmvi.py:365\u001b[0m, in \u001b[0;36mDis2pmVI.train\u001b[0;34m(self, max_epochs, use_gpu, train_size, validation_size, batch_size, early_stopping, plan_kwargs, cf_weight, beta, clf_weight, adv_clf_weight, adv_period, n_cf, **trainer_kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m trainer_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearly_stopping_monitor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m runner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_runner_cls(\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    359\u001b[0m     training_plan\u001b[38;5;241m=\u001b[39mtraining_plan,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrainer_kwargs,\n\u001b[1;32m    364\u001b[0m )\n\u001b[0;32m--> 365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/scvi/train/_trainrunner.py:99\u001b[0m, in \u001b[0;36mTrainRunner.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_splitter, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_val\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_plan\u001b[38;5;241m.\u001b[39mn_obs_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_splitter\u001b[38;5;241m.\u001b[39mn_val\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_plan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_splitter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_history()\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# data splitter only gets these attrs after fit\u001b[39;00m\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/scvi/train/_trainer.py:186\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], PyroTrainingPlan):\n\u001b[1;32m    181\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[1;32m    182\u001b[0m         action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    183\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    184\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`LightningModule.configure_optimizers` returned `None`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    185\u001b[0m     )\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\n\u001b[0;32m--> 532\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(\n\u001b[1;32m    562\u001b[0m     model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    567\u001b[0m     ckpt_path,\n\u001b[1;32m    568\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    570\u001b[0m )\n\u001b[0;32m--> 571\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 980\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1023\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:202\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:355\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher\u001b[38;5;241m.\u001b[39msetup(combined_loader)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:133\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:221\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    219\u001b[0m             batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautomatic_optimization\u001b[38;5;241m.\u001b[39mrun(trainer\u001b[38;5;241m.\u001b[39moptimizers[\u001b[38;5;241m0\u001b[39m], kwargs)\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 221\u001b[0m             batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# update non-plateau LR schedulers\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# update epoch-interval ones only when we are at the end of training epoch\u001b[39;00m\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/manual.py:91\u001b[0m, in \u001b[0;36m_ManualOptimization.run\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_run_start()\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mStopIteration\u001b[39;00m):  \u001b[38;5;66;03m# no loop to break at this level\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_run_end()\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/manual.py:111\u001b[0m, in \u001b[0;36m_ManualOptimization.advance\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m kwargs  \u001b[38;5;66;03m# release the batch from memory\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:294\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 294\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    297\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:380\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mtrain_step_context():\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, TrainingStep)\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair/dis2pm_dev/dis2pm/trainingplan_m.py:254\u001b[0m, in \u001b[0;36mDis2pTrainingPlan.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    251\u001b[0m         loss \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m ce_loss_sum \u001b[38;5;241m*\u001b[39m kappa \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madv_clf_weight\n\u001b[1;32m    253\u001b[0m     opt1\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     opt1\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# train adversarial classifier  # change only parameters of adversarial classifier\u001b[39;00m\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/core/module.py:1046\u001b[0m, in \u001b[0;36mLightningModule.manual_backward\u001b[0;34m(self, loss, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_is_manual_optimization(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanual_backward\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1046\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:205\u001b[0m, in \u001b[0;36mStrategy.backward\u001b[0;34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    203\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpre_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpost_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_backward(closure_loss)\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py:69\u001b[0m, in \u001b[0;36mPrecisionPlugin.backward\u001b[0;34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     52\u001b[0m     tensor: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     57\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/lightning/pytorch/core/module.py:1064\u001b[0m, in \u001b[0;36mLightningModule.backward\u001b[0;34m(self, loss, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fabric\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1064\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/torch/autograd/__init__.py:193\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    189\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m \\\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mtuple\u001b[39m(inputs) \u001b[38;5;28;01mif\u001b[39;00m inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[1;32m    192\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[0;32m--> 193\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[0;32m~/analysis/dis2p_trials/scfair_20231003/scfair_dev_20231003_env/lib/python3.10/site-packages/torch/autograd/__init__.py:88\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mones_like(out, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format))\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "# train params\n",
    "epochs = 50 #400\n",
    "batch_size = 4 #128\n",
    "cf_weight = 1\n",
    "beta = 1\n",
    "clf_weight = 50\n",
    "adv_clf_weight = 10\n",
    "adv_period = 1\n",
    "n_cf = 1\n",
    "\n",
    "# architecture params\n",
    "n_layers=1\n",
    "\n",
    "train_dict = {'max_epochs': epochs, 'batch_size': batch_size, 'cf_weight': cf_weight,\n",
    "              'beta': beta, 'clf_weight': clf_weight, 'adv_clf_weight': adv_clf_weight,\n",
    "              'adv_period': adv_period, 'n_cf': n_cf}\n",
    "\n",
    "module_name = 'dis2pm'\n",
    "pre_path = f'models/{module_name}'\n",
    "if not os.path.exists(pre_path):\n",
    "    os.makedirs(pre_path)\n",
    "\n",
    "# specify a name for your model\n",
    "model_name =  f'{today},{module_name},{data_name},' + f'n_layers={n_layers},' + ','.join(k + '=' + str(v) for k, v in train_dict.items())\n",
    "\n",
    "# load model (if trained before)\n",
    "# try:\n",
    "#     model = Dis2pmVI.load(f\"{pre_path}/{model_name}\", adata=adata)\n",
    "\n",
    "# # trains the model (if not trained before) and save it into: pre_path + model_name\n",
    "# except:\n",
    "\n",
    "Dis2pmVI.setup_anndata(\n",
    "    adata,\n",
    "    layer='counts',\n",
    "    categorical_covariate_keys=cats,\n",
    "    continuous_covariate_keys=[]\n",
    ")\n",
    "print(adata)\n",
    "model = Dis2pmVI(adata, n_genes=1000, n_regions=200, n_layers=n_layers)\n",
    "model.train( **train_dict, )\n",
    "model.save(f\"{pre_path}/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd305cfd-5cc0-485a-be56-56e9b274a2f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dis2pmVAE.sub_forward_acc() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 93\u001b[0m\n\u001b[1;32m     84\u001b[0m Dis2pmVI\u001b[38;5;241m.\u001b[39msetup_anndata(\n\u001b[1;32m     85\u001b[0m     adata,\n\u001b[1;32m     86\u001b[0m     layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounts\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     87\u001b[0m     categorical_covariate_keys\u001b[38;5;241m=\u001b[39mcats,\n\u001b[1;32m     88\u001b[0m     continuous_covariate_keys\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# model = Dis2pmVI(adata, n_genes=1000, n_regions=200, n_layers=n_layers)\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_module_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub_forward_acc\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_covs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_cov_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m#model.Dis2pmVAE.sub_forward_acc(idx=idx + 1, x=x_, cat_covs=cat_cov_)\u001b[39;00m\n\u001b[1;32m     97\u001b[0m n_cats_per_cov \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madata_manager\u001b[38;5;241m.\u001b[39mget_state_registry(\n\u001b[1;32m     99\u001b[0m         REGISTRY_KEYS\u001b[38;5;241m.\u001b[39mCAT_COVS_KEY\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    103\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: Dis2pmVAE.sub_forward_acc() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "# n_layers=1\n",
    "# epochs = 50 #400\n",
    "# batch_size = 4 #128\n",
    "# cf_weight = 1\n",
    "# beta = 1\n",
    "# clf_weight = 50\n",
    "# adv_clf_weight = 10\n",
    "# adv_period = 1\n",
    "# n_cf = 1\n",
    "# n_genes=1000\n",
    "# n_regions=200\n",
    "\n",
    "n_latent_shared = 10\n",
    "n_input_regions = 200\n",
    "n_layers= 1 \n",
    "n_hidden=128 \n",
    "deeply_inject_covariates=True,\n",
    "use_batch_norm=True,\n",
    "use_layer_norm=False,\n",
    "n_cats_per_cov = (11, 4, 2, 6)\n",
    "\n",
    "x_decoder_acc =  DecoderPeakVI(\n",
    "                    n_latent_shared,\n",
    "                    n_input_regions,\n",
    "                    n_cat_list=n_cats_per_cov,\n",
    "                    n_layers=n_layers,\n",
    "                    n_hidden=n_hidden,\n",
    "                    deep_inject_covariates=deeply_inject_covariates,\n",
    "                    use_batch_norm=use_batch_norm,\n",
    "                    use_layer_norm=use_layer_norm,\n",
    "                )\n",
    "    \n",
    "idx=1\n",
    "x_=torch.tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  2.,\n",
    "          1.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "          0.,  4.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
    "          0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  2.,\n",
    "          6.,  2.,  1.,  5.],\n",
    "        [ 0.,  0.,  7.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
    "          1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  2.,  0.,  0.,  0.,  1.,\n",
    "          0.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
    "          0.,  2.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  2.,  0.,  0.,  0.,  0.,  0.,\n",
    "          1.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          3.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,\n",
    "          0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,\n",
    "          0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,\n",
    "          0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0., 10., 26., 38.,\n",
    "         34., 22., 14., 23.],\n",
    "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.]] )\n",
    "\n",
    "\n",
    "cat_cov_ = torch.tensor( [[8., 0., 1., 2.],\n",
    "        [2., 2., 1., 1.],\n",
    "        [2., 0., 1., 2.],\n",
    "        [8., 3., 0., 4.]] )\n",
    "detach_x=False\n",
    "detach_z=False\n",
    "\n",
    "\n",
    "Dis2pmVI.setup_anndata(\n",
    "    adata,\n",
    "    layer='counts',\n",
    "    categorical_covariate_keys=cats,\n",
    "    continuous_covariate_keys=[]\n",
    ")\n",
    "\n",
    "# model = Dis2pmVI(adata, n_genes=1000, n_regions=200, n_layers=n_layers)\n",
    "\n",
    "model._module_cls.sub_forward_acc(idx=idx + 1, x=x_, cat_covs=cat_cov_)\n",
    "#model.Dis2pmVAE.sub_forward_acc(idx=idx + 1, x=x_, cat_covs=cat_cov_)\n",
    "\n",
    "\n",
    "n_cats_per_cov = (\n",
    "    self.adata_manager.get_state_registry(\n",
    "        REGISTRY_KEYS.CAT_COVS_KEY\n",
    "    ).n_cats_per_key\n",
    "    if REGISTRY_KEYS.CAT_COVS_KEY in self.adata_manager.data_registry\n",
    "    else None\n",
    ")\n",
    "# self.module = self._module_cls(\n",
    "#     #n_input_genes=self.summary_stats.n_vars,\n",
    "#     n_input_genes=n_genes,\n",
    "#     n_input_regions=n_regions,\n",
    "#     n_cats_per_cov=n_cats_per_cov,\n",
    "#     n_hidden=n_hidden,\n",
    "#     n_latent_shared=n_latent_shared,\n",
    "#     n_latent_attribute=n_latent_attribute,\n",
    "#     n_layers=n_layers,\n",
    "#     dropout_rate=dropout_rate,\n",
    "#     gene_likelihood=gene_likelihood,\n",
    "#     latent_distribution=latent_distribution,\n",
    "#     **model_kwargs,\n",
    "# # )\n",
    "\n",
    "\n",
    "# model1 = Dis2pmVAE(\n",
    "#         n_input_genes=n_genes,\n",
    "#     n_input_regions=n_regions,\n",
    "#     n_cats_per_cov=n_cats_per_cov,\n",
    "#     n_hidden=n_hidden,\n",
    "#     n_latent_shared=n_latent_shared,\n",
    "#     n_latent_attribute=n_latent_attribute,\n",
    "#     n_layers=n_layers,\n",
    "#     dropout_rate=dropout_rate,\n",
    "#     gene_likelihood=gene_likelihood,\n",
    "#     latent_distribution=latent_distribution,\n",
    "#     **model_kwargs,\n",
    "# )\n",
    "    \n",
    "cat_covs =cat_cov_\n",
    "if detach_x:\n",
    "    x_ = x.detach()\n",
    "\n",
    "library = torch.ones(x_.size(dim=0) ) \n",
    "\n",
    "cat_in = torch.split(cat_covs, 1, dim=1)\n",
    "\n",
    "qz, z = (self.z_encoders_list_acc[idx](x_, *cat_in))\n",
    "if detach_z:\n",
    "    z = z.detach()\n",
    "\n",
    "dec_cats = [cat_in[j] for j in range(len(cat_in)) if j != idx-1]\n",
    "\n",
    "x_decoder = x_decoder_acc\n",
    "\n",
    "px_scale, px_r, px_rate, px_dropout = x_decoder(\n",
    "    self.dispersion,\n",
    "    z,\n",
    "    library,\n",
    "    *dec_cats\n",
    ")     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a262059-dbd1-4640-a187-244fa70c5cd9",
   "metadata": {},
   "source": [
    "# get latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd04dd0-7257-43f6-bdc4-fa6608601bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "pre_path = f'models/dis2p'\n",
    "model_name = f'{today},dis2p,HeartAtlas,n_layers=1,max_epochs=400,batch_size=128,cf_weight=1,beta=1,clf_weight=50,adv_clf_weight=10,adv_period=1,n_cf=1'\n",
    "model = Dis2pVI.load(f\"{pre_path}/{model_name}\", adata=adata)\n",
    "\n",
    "# Z_0\n",
    "adata.obsm[f'dis2p_Z_0'] = model.get_latent_representation(nullify_cat_covs_indices=[s for s in range(len(cats))], nullify_shared=False)\n",
    "\n",
    "for i in range(len(cats)):\n",
    "    null_idx = [s for s in range(len(cats)) if s != i]\n",
    "    # Z_i\n",
    "    adata.obsm[f'dis2p_Z_{i+1}'] = model.get_latent_representation(nullify_cat_covs_indices=null_idx, nullify_shared=True)\n",
    "    # Z_{-i}\n",
    "    adata.obsm[f'dis2p_Z_not_{i+1}'] = model.get_latent_representation(nullify_cat_covs_indices=[i], nullify_shared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c58012-2bd3-40d8-a9e0-ee8390f3be6f",
   "metadata": {},
   "source": [
    "# plot UMAP latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f819eae-ee08-4cf7-80cd-567899a500e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc35e301-e181-4f22-84e3-33f8e9df79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cats) + 1):  # loop over all Z_i\n",
    "\n",
    "    latent_name = f'dis2p_Z_{i}'\n",
    "\n",
    "    print(f\"---UMAP for {latent_name}---\")\n",
    "\n",
    "    sc.pp.neighbors(adata, use_rep=f\"{latent_name}\")\n",
    "    sc.tl.umap(adata)\n",
    "\n",
    "    sc.pl.umap(\n",
    "        adata,\n",
    "        color=cats,\n",
    "        ncols=len(cats),\n",
    "        frameon=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e4b169-cab2-42ac-944d-7c647befe717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "scfair_dev_20231003_env",
   "name": "pytorch-gpu.1-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m112"
  },
  "kernelspec": {
   "display_name": "scfair_dev_20231003_env",
   "language": "python",
   "name": "scfair_dev_20231003_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
